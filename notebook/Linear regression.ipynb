{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['Item_Weight', 'Item_Fat_Content', 'Item_Type', 'Item_MRP', 'Outlet_Establishment_Year', 'Outlet_Location', 'Outlet_Type', 'Item_Outlet_Sales']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_train = pd.read_csv(r'C:\\Users\\USER\\Desktop\\sales pred\\Train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\USER\\Desktop\\sales pred\\Test.csv')\n",
    "print(\"Train columns:\", df_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_values, predicted_values):\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    r2 = r2_score(true_values, predicted_values)\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING AND HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in df_train before cleaning:\n",
      "Item_Weight                  0\n",
      "Item_Fat_Content             0\n",
      "Item_Type                    0\n",
      "Item_MRP                     0\n",
      "Outlet_Establishment_Year    0\n",
      "Outlet_Location              0\n",
      "Outlet_Type                  0\n",
      "Item_Outlet_Sales            0\n",
      "Outlet_Age                   0\n",
      "Is_High_Fat                  0\n",
      "Item_MRP_per_kg              1\n",
      "Item_MRP_log                 0\n",
      "Item_MRP_per_kg_log          1\n",
      "Item_Outlet_Sales_log        0\n",
      "dtype: int64\n",
      "NaN counts after cleaning:\n",
      "Item_Weight                  0\n",
      "Item_MRP                     0\n",
      "Outlet_Establishment_Year    0\n",
      "Item_Outlet_Sales            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "categorical_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Type']\n",
    "numerical_cols = ['Item_Weight', 'Item_MRP', 'Outlet_Establishment_Year']\n",
    "\n",
    "# Check NaNs\n",
    "print(\"NaN counts in df_train before cleaning:\")\n",
    "print(df_train.isna().sum())\n",
    "\n",
    "# Clean Item_Fat_Content\n",
    "df_train['Item_Fat_Content'] = df_train['Item_Fat_Content'].replace({'low fat': 'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'})\n",
    "\n",
    "# Fill Item_Weight by Item_Type mean, then global mean if still NaN\n",
    "df_train['Item_Weight'] = df_train.groupby('Item_Type')['Item_Weight'].transform(lambda x: x.fillna(x.mean()))\n",
    "df_train['Item_Weight'] = df_train['Item_Weight'].fillna(df_train['Item_Weight'].mean())\n",
    "\n",
    "# Drop rows where target is NaN\n",
    "df_train = df_train.dropna(subset=['Item_Outlet_Sales'])\n",
    "\n",
    "# Verify no NaNs in key columns\n",
    "print(\"NaN counts after cleaning:\")\n",
    "print(df_train[numerical_cols + ['Item_Outlet_Sales']].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in new features:\n",
      "Item_Weight        0\n",
      "Item_MRP           0\n",
      "Outlet_Age         0\n",
      "Item_MRP_per_kg    0\n",
      "Is_High_Fat        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# New features\n",
    "df_train['Outlet_Age'] = 2025 - df_train['Outlet_Establishment_Year']\n",
    "df_train['Is_High_Fat'] = df_train['Item_Fat_Content'].apply(lambda x: 1 if x == 'Regular' else 0)\n",
    "df_train['Item_MRP_per_kg'] = df_train['Item_MRP'] / df_train['Item_Weight']\n",
    "\n",
    "# Replace inf/nan in Item_MRP_per_kg\n",
    "df_train['Item_MRP_per_kg'] = df_train['Item_MRP_per_kg'].replace([np.inf, -np.inf], np.nan)\n",
    "df_train['Item_MRP_per_kg'] = df_train['Item_MRP_per_kg'].fillna(df_train['Item_MRP_per_kg'].mean())\n",
    "\n",
    "# Update numerical columns\n",
    "numerical_cols = ['Item_Weight', 'Item_MRP', 'Outlet_Age', 'Item_MRP_per_kg']\n",
    "binary_cols = ['Is_High_Fat']\n",
    "\n",
    "# Check for NaNs\n",
    "print(\"NaN counts in new features:\")\n",
    "print(df_train[numerical_cols + binary_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOG TRANSFORM SKEWED FEATURES AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample log-transformed target: 0    16.432124\n",
      "1    14.301108\n",
      "2    15.854976\n",
      "3    14.802883\n",
      "4    15.109030\n",
      "Name: Item_Outlet_Sales_log, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Log transform skewed features and target\n",
    "df_train['Item_MRP_log'] = np.log1p(df_train['Item_MRP'])\n",
    "df_train['Item_MRP_per_kg_log'] = np.log1p(df_train['Item_MRP_per_kg'])\n",
    "df_train['Item_Outlet_Sales_log'] = np.log1p(df_train['Item_Outlet_Sales'])\n",
    "\n",
    "# Update numerical columns for scaling\n",
    "numerical_cols_log = ['Item_Weight', 'Item_MRP_log', 'Outlet_Age', 'Item_MRP_per_kg_log']\n",
    "\n",
    "# Debug\n",
    "print(\"Sample log-transformed target:\", df_train['Item_Outlet_Sales_log'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE-HOT ENCODING CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train columns: ['Item_Weight', 'Item_MRP_log', 'Outlet_Age', 'Item_MRP_per_kg_log', 'Is_High_Fat', 'Item_Fat_Content_Regular', 'Item_Type_Breads', 'Item_Type_Breakfast', 'Item_Type_Canned', 'Item_Type_Dairy', 'Item_Type_Frozen Foods', 'Item_Type_Fruits and Vegetables', 'Item_Type_Hard Drinks', 'Item_Type_Health and Hygiene', 'Item_Type_Household', 'Item_Type_Meat', 'Item_Type_Others', 'Item_Type_Seafood', 'Item_Type_Snack Foods', 'Item_Type_Soft Drinks', 'Item_Type_Starchy Foods']\n",
      "Sample y_train values (log): [15.94304452 11.95870044 14.16800518 16.77487657 16.27285432]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_train_encoded = pd.get_dummies(df_train[categorical_cols], columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Combine with numerical and binary features\n",
    "X = pd.concat([df_train[numerical_cols_log + binary_cols], df_train_encoded], axis=1)\n",
    "y = df_train['Item_Outlet_Sales_log']  # Use log-transformed target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Debug\n",
    "print(\"X_train columns:\", X_train.columns.tolist())\n",
    "print(\"Sample y_train values (log):\", y_train[:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in X_train_scaled:\n",
      "Item_Weight                        0\n",
      "Item_MRP_log                       0\n",
      "Outlet_Age                         0\n",
      "Item_MRP_per_kg_log                0\n",
      "Is_High_Fat                        0\n",
      "Item_Fat_Content_Regular           0\n",
      "Item_Type_Breads                   0\n",
      "Item_Type_Breakfast                0\n",
      "Item_Type_Canned                   0\n",
      "Item_Type_Dairy                    0\n",
      "Item_Type_Frozen Foods             0\n",
      "Item_Type_Fruits and Vegetables    0\n",
      "Item_Type_Hard Drinks              0\n",
      "Item_Type_Health and Hygiene       0\n",
      "Item_Type_Household                0\n",
      "Item_Type_Meat                     0\n",
      "Item_Type_Others                   0\n",
      "Item_Type_Seafood                  0\n",
      "Item_Type_Snack Foods              0\n",
      "Item_Type_Soft Drinks              0\n",
      "Item_Type_Starchy Foods            0\n",
      "dtype: int64\n",
      "NaN counts in X_test_scaled:\n",
      "Item_Weight                        0\n",
      "Item_MRP_log                       0\n",
      "Outlet_Age                         0\n",
      "Item_MRP_per_kg_log                0\n",
      "Is_High_Fat                        0\n",
      "Item_Fat_Content_Regular           0\n",
      "Item_Type_Breads                   0\n",
      "Item_Type_Breakfast                0\n",
      "Item_Type_Canned                   0\n",
      "Item_Type_Dairy                    0\n",
      "Item_Type_Frozen Foods             0\n",
      "Item_Type_Fruits and Vegetables    0\n",
      "Item_Type_Hard Drinks              0\n",
      "Item_Type_Health and Hygiene       0\n",
      "Item_Type_Household                0\n",
      "Item_Type_Meat                     0\n",
      "Item_Type_Others                   0\n",
      "Item_Type_Seafood                  0\n",
      "Item_Type_Snack Foods              0\n",
      "Item_Type_Soft Drinks              0\n",
      "Item_Type_Starchy Foods            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Scale only the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numerical_cols_log] = scaler.fit_transform(X_train[numerical_cols_log])\n",
    "X_test_scaled[numerical_cols_log] = scaler.transform(X_test[numerical_cols_log])\n",
    "\n",
    "# Check for NaNs after scaling\n",
    "print(\"NaN counts in X_train_scaled:\")\n",
    "print(X_train_scaled.isna().sum())\n",
    "print(\"NaN counts in X_test_scaled:\")\n",
    "print(X_test_scaled.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING LINEAR REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on log-transformed target\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions (in log space)\n",
    "y_train_pred_log = model.predict(X_train_scaled)\n",
    "y_test_pred_log = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INVERSE TRANSFORMATION AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample y_train_pred (UGX): [ 3772320.11528229  1426978.03965616  1081410.74138163 14751609.31916894\n",
      " 11862618.9767784 ]\n",
      "Sample y_test_pred (UGX): [10491109.05216125  5752694.8639348   8608805.80375234  1914894.26672928\n",
      "  6645587.38417434]\n"
     ]
    }
   ],
   "source": [
    "# Inverse transform predictions and true values to original UGX scale\n",
    "y_train_pred = np.expm1(y_train_pred_log)  # expm1 reverses log1p\n",
    "y_test_pred = np.expm1(y_test_pred_log)\n",
    "y_train_orig = np.expm1(y_train)\n",
    "y_test_orig = np.expm1(y_test)\n",
    "\n",
    "# Debug\n",
    "print(\"Sample y_train_pred (UGX):\", y_train_pred[:5])\n",
    "print(\"Sample y_test_pred (UGX):\", y_test_pred[:5])\n",
    "\n",
    "# Evaluate on original scale\n",
    "train_mae, train_rmse, train_r2 = evaluate_model(y_train_orig, y_train_pred)\n",
    "test_mae, test_rmse, test_r2 = evaluate_model(y_test_orig, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with Improvements\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5096638.2828 UGX\n",
      "- Mean Absolute Error: 3633812.9552 UGX\n",
      "- R2 Score: 0.3366\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5639155.7250 UGX\n",
      "- Mean Absolute Error: 4263280.0465 UGX\n",
      "- R2 Score: 0.3283\n",
      "===================================\n",
      "Results saved to C:\\Users\\USER\\Desktop\\sales pred\\notebook\\linear_regression_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Linear Regression with Improvements')\n",
    "print('Model performance for Training set')\n",
    "print(f'- Root Mean Squared Error: {train_rmse:.4f} UGX')\n",
    "print(f'- Mean Absolute Error: {train_mae:.4f} UGX')\n",
    "print(f'- R2 Score: {train_r2:.4f}')\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print(f'- Root Mean Squared Error: {test_rmse:.4f} UGX')\n",
    "print(f'- Mean Absolute Error: {test_mae:.4f} UGX')\n",
    "print(f'- R2 Score: {test_r2:.4f}')\n",
    "print('='*35)\n",
    "\n",
    "# Save results\n",
    "file_path = r'C:\\Users\\USER\\Desktop\\sales pred\\notebook\\linear_regression_results.txt'\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write('Linear Regression with Improvements\\n')\n",
    "    f.write('Model performance for Training set\\n')\n",
    "    f.write(f'- Root Mean Squared Error: {train_rmse:.4f} UGX\\n')\n",
    "    f.write(f'- Mean Absolute Error: {train_mae:.4f} UGX\\n')\n",
    "    f.write(f'- R2 Score: {train_r2:.4f}\\n')\n",
    "    f.write('----------------------------------\\n')\n",
    "    f.write('Model performance for Test set\\n')\n",
    "    f.write(f'- Root Mean Squared Error: {test_rmse:.4f} UGX\\n')\n",
    "    f.write(f'- Mean Absolute Error: {test_mae:.4f} UGX\\n')\n",
    "    f.write(f'- R2 Score: {test_r2:.4f}\\n')\n",
    "    f.write('='*35 + '\\n')\n",
    "print(f'Results saved to {file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
